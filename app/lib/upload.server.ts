// app/lib/upload.server.ts (ìµœì¢… ìˆ˜ì •)
import { PassThrough } from "stream";
import { S3Client } from "@aws-sdk/client-s3";
import { Upload } from "@aws-sdk/lib-storage";
import type { UploadHandler } from "@remix-run/node";
import sharp from "sharp";

// S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
const s3Client = new S3Client({
  region: process.env.AWS_REGION!,
  credentials: {
    accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
  },
});

const BUCKET_NAME = process.env.S3_BUCKET_NAME!;

// ìŠ¤íŠ¸ë¦¼ì„ ë°›ì•„ì„œ sharpìœ¼ë¡œ ë³€í™˜í•˜ê³  ë‹¤ì‹œ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
function processImageStream() {
  const passthrough = new PassThrough();
  const sharpStream = sharp()
    .resize({ width: 800, height: 800, fit: "inside", withoutEnlargement: true })
    .webp({ quality: 80 });
  
  return passthrough.pipe(sharpStream);
}

export const s3UploadHandler: UploadHandler = async ({ name, data, filename }) => {
  if (name !== "images" && name !== "newImages") {
    return undefined;
  }

  const processedImageStream = processImageStream();

  // ìŠ¤íŠ¸ë¦¼ì„ S3ë¡œ ì—…ë¡œë“œ
  const upload = new Upload({
    client: s3Client,
    params: {
      Bucket: BUCKET_NAME,
      Key: `uploads/image-${Date.now()}-${filename}.webp`,
      Body: processedImageStream,
      ContentType: "image/webp",
    },
  });

  // ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼ ë°ì´í„°ë¥¼ íŒŒì´í”„ë¡œ ì—°ê²°
  for await (const chunk of data) {
    processedImageStream.write(chunk);
  }
  processedImageStream.end();

  // ğŸ‘‡ ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì •ì‚¬í•­ì…ë‹ˆë‹¤!
  // .done()ì„ í•œ ë²ˆë§Œ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
  const result = await upload.done();

  // ì €ì¥ëœ ê²°ê³¼ì—ì„œ Keyë¥¼ ì‚¬ìš©í•˜ì—¬ URLì„ ë§Œë“­ë‹ˆë‹¤.
  const url = `https://${BUCKET_NAME}.s3.${process.env.AWS_REGION}.amazonaws.com/${result.Key}`;
  return url;
};